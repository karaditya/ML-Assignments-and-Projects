{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of DnCNN_final",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGCJoPCvve1X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d525a0d1-6d57-4a39-b815-16d0794212c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGNk3lNbGmP7"
      },
      "source": [
        "# Patch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QJmLv8uGpiQ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "def gen_patch(img_list):\n",
        "    Patch = []\n",
        "    patch_size = 50\n",
        "    stride = 20\n",
        "    n = len(img_list)\n",
        "    print(n)\n",
        "    for i in range(n):\n",
        "        img = cv2.imread(img_list[i])\n",
        "        for p in range(0, img.shape[0] - patch_size+1, stride):\n",
        "            for q in range(0, img.shape[1] - patch_size+1, stride):\n",
        "                height_slice = slice(p, p+patch_size)\n",
        "                width_slice = slice(q, q+patch_size)\n",
        "                patch = img[height_slice, width_slice, :]\n",
        "                Patch.append(patch)           \n",
        "\n",
        "    return np.array(Patch)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9lBtMy_Gxuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bd2f2e59-de46-4a92-a1ff-6ae1d5513548"
      },
      "source": [
        "train_path = '/content/drive/My Drive/BSR_bsds500/BSR/BSDS500/data/images/train'\n",
        "train_file_list = glob.glob(train_path+'/*.jpg')\n",
        "\n",
        "val_path = '/content/drive/My Drive/BSR_bsds500/BSR/BSDS500/data/images/val'\n",
        "val_file_list = glob.glob(val_path+'/*.jpg')            \n",
        "        \n",
        "Train_patch = gen_patch(train_file_list)\n",
        "Val_patch = gen_patch(val_file_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKjjSaQwlxD"
      },
      "source": [
        "# DnCNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGlS9Uxe6kfg"
      },
      "source": [
        "import time, math\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Subtract\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhHfHniogIpt"
      },
      "source": [
        "class DnCNN_model(tf.Module):\n",
        "  def __init__(self, depth, input_shape, filter, BN = True):\n",
        "    super(DnCNN_model,self).__init__()\n",
        "    self.input_shape = input_shape\n",
        "    self.filters = filters\n",
        "    self.BN = BN\n",
        "    self.depth = depth\n",
        "\n",
        "  def make_model(self):\n",
        "    # Retrieving Filters\n",
        "    F = self.filters\n",
        "    input_shape = self.input_shape\n",
        "    depth = self.depth\n",
        "    input = Input(input_shape)\n",
        "\n",
        "    x = Conv2D(F, (3, 3), padding='same', strides=(1, 1), activation='relu')(input)\n",
        "    \n",
        "    # Middle Block\n",
        "    for layers in range(depth-2):\n",
        "      x = Conv2D(F, (3, 3), padding='same', strides=(1, 1))(x)\n",
        "      if self.BN :\n",
        "        x = BatchNormalization(axis=3, momentum=0.0, epsilon=0.0001)(x)\n",
        "      x = Activation('relu')(x) \n",
        "\n",
        "    # Last Layer\n",
        "    x = Conv2D(3, (3, 3), padding='same', strides=(1, 1))(x) \n",
        "    out = Subtract()([input, x])\n",
        "    model = Model(inputs=[input], outputs=[out])\n",
        "\n",
        "    return model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q61p4hXc1U_u"
      },
      "source": [
        "def PSNR(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    err = y_true - y_pred\n",
        "    mse = K.sum(err*err)/(2*batch_size)\n",
        "    return mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f--QwtcmQxZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc0edb42-5946-4880-edc5-d73b35f93365"
      },
      "source": [
        "depth = 20\n",
        "input_shape = (50,50,3)\n",
        "filters = 64\n",
        "model = DnCNN_model(depth, input_shape, filters, BN = True).make_model()\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss=mse_loss, metrics=[PSNR])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50, 50, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 50, 50, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 50, 50, 64)   36928       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 50, 50, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 50, 50, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 50, 50, 64)   36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 50, 50, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 50, 50, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 50, 50, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 50, 50, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 50, 50, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 50, 50, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 50, 50, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 50, 50, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 50, 50, 64)   36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 50, 50, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 50, 50, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 50, 50, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 50, 50, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 50, 50, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 50, 50, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 50, 50, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 50, 50, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 50, 50, 64)   36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 50, 50, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 50, 50, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 50, 50, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 50, 50, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 50, 50, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 50, 50, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 50, 50, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 50, 50, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 50, 50, 64)   36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 50, 50, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 50, 50, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 50, 50, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 50, 50, 64)   256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 50, 50, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 50, 50, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 50, 50, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 50, 50, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 50, 50, 64)   36928       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 50, 50, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 50, 50, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 50, 50, 3)    1731        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 50, 50, 3)    0           input_1[0][0]                    \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 672,835\n",
            "Trainable params: 670,531\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abxO_7mExCNo"
      },
      "source": [
        "# Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya0jTmjdVZWK"
      },
      "source": [
        "def noise_gen(cleanImg, batch_size = 32, rot = 30, vertical_flip = True):\n",
        "  generator = ImageDataGenerator(rotation_range = rot, vertical_flip = vertical_flip, fill_mode = 'nearest')\n",
        "  for batch in generator.flow(x = cleanImg, batch_size = batch_size, seed = 3 ):\n",
        "    sigma = np.random.randint(5,50)\n",
        "    AWG_noise = np.random.normal(0.0, sigma/255.0, batch.shape)\n",
        "    noisyImg_batch = batch/255.0 + AWG_noise\n",
        "    Target_batch = batch/255.0\n",
        "    yield (noisyImg_batch, Target_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMGn0T1g0Hx9"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_431aiK30M0_"
      },
      "source": [
        "train_dataloader = noise_gen(Train_patch, batch_size = 32, rot = 30, vertical_flip = True)\n",
        "val_dataloader = noise_gen(Val_patch, batch_size = 32, rot = 0, vertical_flip = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zE_Z1mc06SZ"
      },
      "source": [
        "# Training Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxJfEijg05WK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fa9edbe-1c59-406d-93de-5c91981f39f8"
      },
      "source": [
        "import os\n",
        "def create_directory(directory):\n",
        "    '''\n",
        "    Creates a new folder in the specified directory if the folder doesn't exist.\n",
        "    INPUT\n",
        "        directory: Folder to be created, called as \"folder/\".\n",
        "    OUTPUT\n",
        "        New folder in the current directory.\n",
        "    '''\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "path = '/content/drive/My Drive/BSR_bsds500'\n",
        "# Name experiment\n",
        "experiment_name = \"exp-50*50_20st1\"\n",
        "log_path = os.path.join(path,\"log_DnCNN\", experiment_name)\n",
        "# Make directory\n",
        "create_directory(log_path)\n",
        "print(log_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/BSR_bsds500/log_DnCNN/exp-50*50_20st1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Gxa0r32P83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58295ba5-f3ca-4c64-9d8c-08b9a343ceda"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvewhhtB1ZUE"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exOGPd51Ibs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "07c4c2f5-d5aa-46db-f431-bec6b3daa99f"
      },
      "source": [
        "LR = 1e-4   # 1e-4(0.0001) \n",
        "EPOCHS = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Define callbacks for learning rate scheduling, logging and best checkpoints saving\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('{}/{}.h5'.format(log_path, experiment_name), monitor='val_PSNR', save_best_only=True, mode='max'),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_PSNR', factor=0.1, verbose=1, patience=3, mode='max'), ## new_lr = lr * factor # 5\n",
        "    keras.callbacks.EarlyStopping(monitor='val_PSNR', min_delta=0, verbose=1, patience=5, mode='max', restore_best_weights=True), # 8\n",
        "    keras.callbacks.CSVLogger('{}/training.csv'.format(log_path))\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataloader, \n",
        "    steps_per_epoch=len(Train_patch)*3//batch_size, \n",
        "    epochs=EPOCHS, \n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    validation_data=val_dataloader, \n",
        "    validation_steps=len(Val_patch)//batch_size\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5775/5775 [==============================] - 672s 116ms/step - loss: 36.1974 - PSNR: 23.3570 - val_loss: 13.7446 - val_PSNR: 25.6423\n",
            "Epoch 2/20\n",
            "5775/5775 [==============================] - 670s 116ms/step - loss: 9.1676 - PSNR: 27.6798 - val_loss: 9.9739 - val_PSNR: 26.9388\n",
            "Epoch 3/20\n",
            "5775/5775 [==============================] - 668s 116ms/step - loss: 6.2212 - PSNR: 29.2449 - val_loss: 14.9420 - val_PSNR: 26.3904\n",
            "Epoch 4/20\n",
            "5775/5775 [==============================] - 669s 116ms/step - loss: 5.3221 - PSNR: 29.9613 - val_loss: 11.4831 - val_PSNR: 27.1683\n",
            "Epoch 5/20\n",
            "5775/5775 [==============================] - 669s 116ms/step - loss: 4.8611 - PSNR: 30.3775 - val_loss: 8.8175 - val_PSNR: 27.5311\n",
            "Epoch 6/20\n",
            "5775/5775 [==============================] - 668s 116ms/step - loss: 4.4670 - PSNR: 30.7722 - val_loss: 13.5815 - val_PSNR: 26.6943\n",
            "Epoch 7/20\n",
            "5775/5775 [==============================] - 668s 116ms/step - loss: 4.2890 - PSNR: 30.9360 - val_loss: 10.0477 - val_PSNR: 27.9900\n",
            "Epoch 8/20\n",
            "5775/5775 [==============================] - 668s 116ms/step - loss: 4.1623 - PSNR: 31.0820 - val_loss: 8.7472 - val_PSNR: 27.4569\n",
            "Epoch 9/20\n",
            "5775/5775 [==============================] - 668s 116ms/step - loss: 4.0451 - PSNR: 31.2167 - val_loss: 7.6952 - val_PSNR: 27.8567\n",
            "Epoch 10/20\n",
            "5754/5775 [============================>.] - ETA: 2s - loss: 3.9021 - PSNR: 31.3809"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBCRnaWcvJJ9"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(6, 6)\n",
        "plt.plot(history.history['PSNR'])\n",
        "plt.plot(history.history['val_PSNR'])\n",
        "plt.title('Model PSNR Metric')\n",
        "plt.ylabel('PSNR (dB)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.grid()\n",
        "plt.legend(['Train', 'Test'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(6, 6)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.grid()\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
